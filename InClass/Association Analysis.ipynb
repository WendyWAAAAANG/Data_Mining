{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Association Analysis Application -  Market Basket Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One specific application of association analysis is often called market basket analysis. The most commonly cited example of market basket analysis is the so-called *beer and diapers* case. The basic story is that a large retailer was able to mine their transaction data and find an unexpected purchase pattern of individuals that were buying beer and baby diapers at the same time. The story is an illustrative (and entertaining) example of the types of insights that can be gained by mining transactional data. While these types of associations are normally used for looking at sales transactions; the basic analysis can be applied to other situations like *click stream tracking*, *spare parts ordering* and *online recommendation engines* - just to name a few.\n",
    "\n",
    "**mlxtend** (machine learning extensions) is a Python library of useful tools for the day-to-day data science tasks, which provides implementation for frequent pattern mining algorithms Apriori and FP-Growth. The rest of this notebook will walk through an example of using this library to analyze a relatively large online retail\n",
    "(http://archive.ics.uci.edu/ml/datasets/Online+Retail) data set and try to find interesting purchase combinations. By the end of this notebook, you should be familiar enough with the basic approach to apply it to your own data sets.\n",
    "- Install mlxtend using ``pip install mlxtend``\n",
    "- **Dataset:** ``Online Retail.xlsx`` is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ``pandas`` and ``MLxtend`` imported and read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "df = pd.read_excel('Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a little cleanup we need to do. First, some of the descriptions have spaces that need to be removed. Weâ€™ll also drop the rows that don't have invoice numbers and remove the credit transactions (those with invoice numbers containing C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing whitespace from descriptions\n",
    "df['Description'] = df['Description'].str.strip()\n",
    "\n",
    "# Drop rows that don't have invoice numbers\n",
    "df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove credit transactions (those with invoice numbers containing 'C')\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
    "df = df[~df['InvoiceNo'].str.contains('C')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis requires that all the data for a transaction be included in 1 row and the items should be *1-\n",
    "hot encoded*. Therefore, need to consolidate items into 1 transaction per row, with each product 1 hot encoded. \n",
    "- For sake of keeping the dataset small, we look at sales for France only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by invoiceNo and Description, keep record of the quantity\n",
    "df[df['Country']=='France'].groupby(['InvoiceNo','Description'])['Quantity'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = (df[df['Country'] == 'France']\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert units to 1 hot encoded values\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return False\n",
    "    if x >= 1:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_sets = basket.applymap(encode_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop postage column since that charge is not one we wish to explore  \n",
    "# postage column is used to indicate if the customer paid for postage or not\n",
    "basket_sets.drop('POSTAGE', inplace=True, axis=1)\n",
    "basket_sets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For transforming the transactions into 1-hot encoded format, can also use ``TransactionEncoder()`` in ``mlxtend.preprocessing`` directly, refer to [User Guide](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/) for more details.\n",
    "\n",
    "Now that the data is structured properly, we can generate frequent item sets that have a support of at least 7% (this number was chosen in order to get enough useful examples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up the frequent itemsets\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets.values[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can generate the association rules with their corresponding support, confidence and lift.\n",
    "- In each rule in the form of ``{item1}->{item2}``, the ``{item1}`` is the **antecedent** and ``{item2}`` is the **consequent**. Both the antecedent and consequent can have multiple items.\n",
    "\n",
    "**Evaluation metrics**\n",
    "\n",
    "For each rule, five metrics are given ``support``, ``confidence``, ``lift``, ``leverage`` and ``conviction``. \n",
    "- **Leverage** is the difference ofÂ $ð‘‹$ and $ð‘Œ$Â appearing together in the data set and what would be expected ifÂ  $ð‘‹$ and $ð‘Œ$ are statistically dependent. $$leverage(X\\rightarrow Y)= support(X\\rightarrow Y)-support(X)support(Y)$$. \n",
    "    - Range is (-1,1) (0 indicates independence). \n",
    "    - The rational in a sales setting is to find out how many more units (items ð‘‹Â and ð‘Œ together) are sold than expected from the independent sells.\n",
    "- **Conviction** compares the probability that $ð‘‹$ appears without $ð‘Œ$ if they were dependent with the actual frequency of the appearance of $ð‘‹$ without $ð‘Œ$. $$conviction(X\\rightarrow Y)= \\frac{sup(X)sup(\\overline{Y})}{sup(X\\cup \\overline{Y})}= \\frac{p(X)(1-p(Y))}{p(X)-p(X\\cup Y)}=\\frac{1-p(Y)}{1-p(Y|X)}$$\n",
    "    - Range (0,inf)\n",
    "    - Conviction can be interpreted as the ratio of expected frequency that the rule makes an incorrect prediction (if $ð‘‹$ and $ð‘Œ$ were independent) divided by the observed frequency of incorrect predictions.\n",
    "    - A high conviction value means that the consequent ($ð‘Œ$) is highly depending on the antecedent ($ð‘‹$). \n",
    "In the case of a perfect confidence score, the denominator becomes 0 (due to 1 - 1) for which the conviction score is defined as 'inf'.\n",
    "    - If antecedents and consequents are independent, the conviction is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rules\n",
    "# Metric to evaluate if a rule is of interest\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the tricky part is figuring out what this tells us. For instance, we can see that there are quite a few rules with a high lift value which means that it occurs more frequently than would be expected. We can also see several where the confidence is high as well. This part of the analysis is where the domain knowledge will come in handy. \n",
    "\n",
    "Next, we will just look for a couple of illustrative examples. \n",
    "For example, using a large lift (6) and high confidence (0.8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[ (rules['lift'] >= 6) &\n",
    "       (rules['confidence'] >= 0.8) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the rules, it seems that the green and red alarm clocks are purchased together and the red paper cups, napkins and plates are purchased together.\n",
    "\n",
    "At this point, you may want to look at how much opportunity there is to use the popularity of one product to drive sales of another. For instance, we can see that we sell 340 Green Alarm clocks but only 316 Red Alarm Clocks so maybe we can drive more Red Alarm Clock sales through recommendations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket['ALARM CLOCK BAKELIKE GREEN'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket['ALARM CLOCK BAKELIKE RED'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is also interesting is to see how the combinations vary by country of purchase. Letâ€™s check out what some popular combinations might be in Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket2 = (df[df['Country'] ==\"Germany\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "basket_sets2 = basket2.applymap(encode_units)\n",
    "\n",
    "basket_sets2.drop('POSTAGE', inplace=True, axis=1)\n",
    "\n",
    "frequent_itemsets2 = apriori(basket_sets2, min_support=0.05, use_colnames=True)\n",
    "\n",
    "rules2 = association_rules(frequent_itemsets2, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "rules2[ (rules2['lift'] >= 4) &\n",
    "        (rules2['confidence'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that in addition Germans love Plasters in Tin Spaceboy and Woodland Animals.\n",
    "In all seriousness, an analyst that has familiarity with the data would probably have a dozen different questions that this type of analysis could drive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples of frequent pattern mining using ``mlxtend``, please refer to the [API](http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/) and [User Guide](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/) of ``mlxtend.frequent_patterns``."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
